{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 贝叶斯拼写检查器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(r|w) = P(w|r)P(r) \\\\\n",
    "w -> 用户错误拼写的词 \\\\\n",
    "r -> 该错拼词对应的正确词\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设用户的错误只有3种: 多输/少输/输错1个字符\n",
    "\n",
    "solit 有可能是 split, 也有可能是solid, 仅仅考虑词频效果不太好, 结合context效果会更好\n",
    "\n",
    "注意: solit实际上更可能是split, 因为o和p的键紧挨着, 输入时比较容易按错, 考虑各字母在键盘上的距离应该会比考虑上下文效果更好, 只需要建立字母距离矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesSpellChecker(object):\n",
    "    def __init__(self, corpus_file=r'D:/CS/dataset/NLP/big.txt'):      # corpus文件用于建立词典, 要求涵盖大量词\n",
    "        with open(corpus_file, 'r', encoding='utf-8') as f:\n",
    "            bigwords = f.read().lower()\n",
    "            bigwords = re.sub('[\\n\\t*()#~!?]*', '', bigwords)\n",
    "\n",
    "        tok = Tokenizer()\n",
    "        tok.fit_on_texts([bigwords])\n",
    "\n",
    "        all_words = sum(tok.word_counts.values())    # 总词数, 包含重复词\n",
    "        self.freq_dict = {}\n",
    "        for word, freq in tok.word_counts.items():\n",
    "            self.freq_dict[word] = freq / all_words     # 共 74506 个不同词\n",
    "            \n",
    "    def edit_distance(self, str1, str2):\n",
    "        matrix = [[i+j for j in range(len(str2) + 1)] for i in range(len(str1) + 1)]\n",
    "        for i in range(1,len(str1)+1):\n",
    "            for j in range(1,len(str2)+1):\n",
    "                if str1[i-1] == str2[j-1]:\n",
    "                    d = 0\n",
    "                else:\n",
    "                    d = 1\n",
    "                matrix[i][j] = min(matrix[i-1][j]+1,matrix[i][j-1]+1,matrix[i-1][j-1]+d)\n",
    "\n",
    "        return matrix[len(str1)][len(str2)]\n",
    "    \n",
    "    def get_sim_word(self, word_check):\n",
    "        len_word = [word for word in self.freq_dict.keys() if (len(word) - len(word_check) >= -1) or \\\n",
    "                   (len(word) - len(word_check) <= 1)]\n",
    "        candidate_words = []\n",
    "        for word in len_word:\n",
    "            distance = self.edit_distance(word_check, word)\n",
    "            if distance == 1:\n",
    "                candidate_words.append(word)\n",
    "                \n",
    "        return candidate_words\n",
    "    \n",
    "    def check(self, word_check, verbose=True):\n",
    "        if word_check in self.freq_dict.keys():\n",
    "            print('No problem')\n",
    "            return\n",
    "        else:\n",
    "            candidate_words = self.get_sim_word(word_check)\n",
    "            if verbose:   # 打印过程\n",
    "                pass\n",
    "            candidate_words_freq = [self.freq_dict[word] for word in candidate_words]\n",
    "            correct_word_index = np.argmax(candidate_words_freq)   # 挑选频率最大的候选词\n",
    "            correct_word = candidate_words[correct_word_index]\n",
    "            return correct_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "BayesChecker = BayesSpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'know'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BayesChecker.check('kmow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'block'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BayesChecker.check('blovk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bible'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BayesChecker.check('bibble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'solid'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BayesChecker.check('solit')   # 有可能是 split, 但是 split 的频率稍小于solid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solit 有可能是 split, 但是 split 的频率稍小于solid, 对于出现次数很少的词, 仅仅用P(r)效果不太好, 最好能结合context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检测时间约3s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
