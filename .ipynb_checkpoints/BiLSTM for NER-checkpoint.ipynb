{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM + CRF for NER\n",
    "BiLSTM的输入时文档向量, 并不需要对文档向量padding到一致的长度, 因为对应1个文档, BiLSTM输出1个feats矩阵(len_doc, num_tag), 将feats矩阵输入CRF, CRF最主要是要训练其转移矩阵(tag->tag), 所以即使feats矩阵行数不一, CRF都能用feats训练转移矩阵\n",
    "\n",
    "官方实现: https://pytorch.apachecn.org/docs/1.0/nlp_advanced_tutorial.html?h=Bidirection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "import nltk\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sentence = 10000\n",
    "with open(r'D:/CS/dataset/NLP/命名实体识别/单个字特征数据集/example.train', 'r', \n",
    "          encoding='utf-8') as f:\n",
    "    i = 0;\n",
    "    a = []\n",
    "    while(i < num_sentence):     # 读取了10000句预料\n",
    "        content = f.readline()\n",
    "        if content == '\\n':\n",
    "            i += 1\n",
    "        a.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(temp_list):\n",
    "    index_list = []\n",
    "    for i in range(len(temp_list)):\n",
    "        if temp_list[i] == '\\n':\n",
    "            index_list.append(i)\n",
    "    \n",
    "    pointer = 0\n",
    "    sentence_list = []\n",
    "    for index in index_list:\n",
    "        sentence_list.append(temp_list[pointer : index])\n",
    "        pointer = index + 1\n",
    "    return sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = get_sentences(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['但 O\\n',\n",
       " '是 O\\n',\n",
       " '， O\\n',\n",
       " '金 O\\n',\n",
       " '融 O\\n',\n",
       " '危 O\\n',\n",
       " '机 O\\n',\n",
       " '也 O\\n',\n",
       " '可 O\\n',\n",
       " '能 O\\n',\n",
       " '来 O\\n',\n",
       " '自 O\\n',\n",
       " '内 O\\n',\n",
       " '部 O\\n',\n",
       " '。 O\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[-2]   # 最后一句没有句号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去掉'\\n'和句号\n",
    "for sentence in sentence_list:\n",
    "    try:\n",
    "        sentence.remove('。 O\\n')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for i in range(len(sentence)):\n",
    "        sentence[i] = tuple(sentence[i].strip('\\n').split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('首', 'B-ORG'),\n",
       " ('届', 'I-ORG'),\n",
       " ('立', 'I-ORG'),\n",
       " ('法', 'I-ORG'),\n",
       " ('会', 'I-ORG'),\n",
       " ('选', 'O'),\n",
       " ('举', 'O'),\n",
       " ('是', 'O'),\n",
       " ('“', 'O'),\n",
       " ('港', 'B-LOC'),\n",
       " ('人', 'O'),\n",
       " ('治', 'O'),\n",
       " ('港', 'B-LOC'),\n",
       " ('”', 'O'),\n",
       " ('重', 'O'),\n",
       " ('要', 'O'),\n",
       " ('一', 'O'),\n",
       " ('步', 'O')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除特殊符号\n",
    "stop_words = '[a-zA-Z0-9’\\n·\\s＊!\"：#$%&\\'()◆●（）＠②*+,-./:;<=>?@，。?★、…【】《》？——“”‘’！[\\$$^_`{|}~]+'\n",
    "sentence_list = [[(word, tag) for word, tag in sentence if word not in stop_words] for sentence in sentence_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('首', 'B-ORG'),\n",
       " ('届', 'I-ORG'),\n",
       " ('立', 'I-ORG'),\n",
       " ('法', 'I-ORG'),\n",
       " ('会', 'I-ORG'),\n",
       " ('选', 'O'),\n",
       " ('举', 'O'),\n",
       " ('是', 'O'),\n",
       " ('港', 'B-LOC'),\n",
       " ('人', 'O'),\n",
       " ('治', 'O'),\n",
       " ('港', 'B-LOC'),\n",
       " ('重', 'O'),\n",
       " ('要', 'O'),\n",
       " ('一', 'O'),\n",
       " ('步', 'O')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [[word for word, tag in sentence] for sentence in sentence_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总词数:  3819\n",
      "最大文档长度 550\n"
     ]
    }
   ],
   "source": [
    "# 总词数\n",
    "dic = Dictionary(docs)\n",
    "vocab_size = max(dic.keys()) + 1\n",
    "print('总词数: ', vocab_size)     # 词id从0开始, 最大id 3818\n",
    "\n",
    "# 寻找最大句长\n",
    "sentences_len = [len(doc) for doc in docs]\n",
    "max_len_a_doc = max(sentences_len)\n",
    "print('最大文档长度', max_len_a_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看sentences_len发现绝大多数文档长度在120以内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_a_doc = 120\n",
    "trainY = [[tag for word, tag in sentence] for sentence in sentence_list]    # padding之前\n",
    "\n",
    "my_dic = dict([('O',0), ('B-LOC', 1), ('I-LOC', 2),\n",
    "            ('B-PER', 3), ('I-PER', 4), ('B-ORG', 5), ('I-ORG', 6)])\n",
    "def tag2idx(tag):\n",
    "    return my_dic[tag]\n",
    "\n",
    "# 先将tag映射为idx, 再对idx序列padding, 由于'O'对应idx为0, 所以句子padding部分都视作'O', 对应数字0\n",
    "# 不能用padding, 会使 B-LOC, I-LOC 都变成 B, I\n",
    "trainY_vec = [[my_dic[tag] for tag in sentence] for sentence in trainY]\n",
    "trainY_vec = sequence.pad_sequences(trainY_vec, maxlen=max_len_a_doc, value=0, padding='post')\n",
    "trainY_vec = torch.LongTensor(trainY_vec)\n",
    "trainY_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   7,   12,    6,   10,    4,    8,    3,    2,   13,    0,   11,\n",
       "         13,    1,   14,    9,    7,    5, 3819, 3819, 3819, 3819, 3819,\n",
       "       3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "       3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "       3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "       3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "       3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "       3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "       3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "       3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "       3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文本向量化\n",
    "doc_vec_list = [dic.doc2idx(doc) for doc in docs]\n",
    "# 不能填充-1 因为embedding矩阵中没有-1索引\n",
    "padded_doc_vec_list = sequence.pad_sequences(doc_vec_list, maxlen=120, value=3819, padding='post')\n",
    "trainX = np.array(padded_doc_vec_list)\n",
    "trainX[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM\n",
    "获取BiLSTM的输出feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "embedding_dim = 128\n",
    "lstm_dim = 128\n",
    "num_tag = 7\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, num_tag, embedding_dim, lstm_dim):  # vocab_size + padding的-1\n",
    "        super(Net, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_tag = num_tag\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_dim, num_layers=1, bidirectional=True)\n",
    "        self.lstm2tag = nn.Linear(lstm_dim*2, num_tag)   # BiLSTM 会把正反向lstm每个时间步的输出拼接为1行\n",
    "#         self.lstm2tag = nn.Softmax(num_tag)\n",
    "    def forward(self, x):\n",
    "        x = self.word_embeds(x)\n",
    "        x, hidden = self.lstm(x)\n",
    "        x = self.lstm2tag(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   7,   12,    6,   10,    4,    8,    3,    2,   13,    0,   11,   13,\n",
       "           1,   14,    9,    7,    5, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "        3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "        3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "        3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "        3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "        3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "        3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "        3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "        3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX = torch.LongTensor(trainX)\n",
    "trainX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0332, -0.1004,  0.1632, -0.0808, -0.0067,  0.1000,  0.0260],\n",
       "         [ 0.0974, -0.0688,  0.1360, -0.0215,  0.1057, -0.0165,  0.0161],\n",
       "         [ 0.0682, -0.0807,  0.0579, -0.0824, -0.1232,  0.0390, -0.0255],\n",
       "         [ 0.1617,  0.0086, -0.0476,  0.0115,  0.0057,  0.0495,  0.0105],\n",
       "         [-0.0037,  0.0084,  0.0238, -0.0170,  0.0337,  0.1049,  0.0563],\n",
       "         [-0.0327, -0.0249, -0.0067, -0.0044,  0.0743,  0.0092,  0.0237],\n",
       "         [ 0.1097, -0.0926,  0.1432, -0.0593, -0.0714, -0.0344,  0.0445],\n",
       "         [ 0.0453, -0.1467, -0.0797, -0.0966, -0.0020, -0.0579,  0.0122],\n",
       "         [-0.0499, -0.1244,  0.0158, -0.0457, -0.1384, -0.0048,  0.0376],\n",
       "         [ 0.1179, -0.1381,  0.1598,  0.0099, -0.0188,  0.0093, -0.0037],\n",
       "         [ 0.1006, -0.0481, -0.0147, -0.0339,  0.1813,  0.0253,  0.0542],\n",
       "         [-0.0499, -0.1244,  0.0158, -0.0457, -0.1384, -0.0048,  0.0376],\n",
       "         [ 0.0212, -0.1168,  0.0046, -0.0235, -0.0189, -0.0442,  0.0041],\n",
       "         [ 0.0193, -0.2451,  0.0807, -0.1016, -0.1153, -0.0667, -0.0007],\n",
       "         [ 0.0077, -0.1050, -0.0974,  0.0196,  0.0734, -0.0581, -0.0466],\n",
       "         [ 0.0332, -0.1004,  0.1632, -0.0808, -0.0067,  0.1000,  0.0260],\n",
       "         [ 0.0230, -0.0101, -0.1054, -0.0259, -0.0245,  0.1004,  0.1137],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373],\n",
       "         [ 0.0502, -0.1023,  0.1370,  0.0450, -0.0581, -0.0009, -0.0373]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net(vocab_size+1, num_tag, embedding_dim, lstm_dim)\n",
    "feats = net(trainX[0:1])\n",
    "feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 尝试单独使用BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 120])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 120])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9050, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.8987, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.8977, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.8888, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.8849, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.8722, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.8457, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.8341, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.8145, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.8686, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.7925, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.7831, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.7636, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.8610, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.8762, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.6947, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.6428, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.7525, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.6755, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.6425, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.5839, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.5574, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.5570, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.5338, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.4670, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.4475, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.4453, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.4153, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.3785, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.3309, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.4089, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.2852, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.3335, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.2894, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.3681, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.6035, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.2158, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.1274, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.5054, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.3430, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.3145, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0266, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.2008, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0023, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0647, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.2198, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0098, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.2539, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.8673, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.8522, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.9663, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.8019, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.8034, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.3597, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0213, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0427, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0023, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.1400, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0076, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.1257, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6762, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.8371, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9673, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7462, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7349, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7563, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7327, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7582, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0138, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9394, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6068, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5677, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6300, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7409, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6663, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5594, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4907, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0355, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6436, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5350, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4829, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5156, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6221, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6978, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5376, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7415, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4368, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7190, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5132, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9128, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4230, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.3503, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5906, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5889, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5826, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5673, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4282, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9910, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4757, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4286, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9601, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4021, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.8564, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5519, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5256, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0704, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3131, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9524, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3515, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.3490, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5961, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5344, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4429, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7841, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7810, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5376, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6407, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5847, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4030, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3857, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4961, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3938, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4090, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7144, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3108, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5847, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4693, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3305, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5146, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3850, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4034, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.2477, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3735, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5607, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3756, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4961, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.8181, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5753, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6073, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7194, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2820, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6059, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6964, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3075, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7561, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9561, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2310, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2629, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6547, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9376, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4996, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9390, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3695, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.8987, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5230, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4025, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3396, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4033, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4994, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4463, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5746, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3185, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2547, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5414, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2633, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6011, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0581, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2109, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3192, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2152, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2653, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3661, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6863, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4691, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7102, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6286, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5714, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2916, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3773, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2203, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7702, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3904, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6062, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3101, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7289, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6652, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3896, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1841, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3355, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3519, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3013, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3895, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5050, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3455, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5808, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.8513, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6218, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3841, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4718, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4741, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2501, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5638, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3569, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3360, grad_fn=<AddBackward0>) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3602, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6167, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6921, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4142, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4450, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3868, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3829, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4982, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6447, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3941, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4123, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2325, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6346, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3918, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3387, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3179, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6101, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3412, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4232, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2651, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3759, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2221, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5521, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2507, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5143, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3564, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1539, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2300, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4342, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2992, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4701, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1642, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4352, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7214, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2071, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4334, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1866, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7767, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2947, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7209, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3309, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1931, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3688, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1988, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6441, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5078, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7340, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1679, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2373, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5699, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3399, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4631, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6538, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4979, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5240, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2589, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2726, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3819, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3770, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4167, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6484, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4689, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9271, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1398, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6648, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2973, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5575, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5473, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2618, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4098, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5613, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2493, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1657, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4411, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5832, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4048, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5025, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1848, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3277, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.8910, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2734, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2875, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4181, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2925, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5242, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4930, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5614, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4084, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9595, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2892, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1579, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1652, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4468, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5312, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5401, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2219, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1198, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4506, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1963, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1391, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2710, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1613, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2047, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2641, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4329, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3367, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0144, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2175, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6633, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1386, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3870, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2625, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1881, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2160, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3338, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5635, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2508, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1273, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5895, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1297, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3528, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5839, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1867, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7613, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0091, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4115, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4718, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2481, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2460, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2219, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6585, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4414, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3578, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2406, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1663, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5218, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2956, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2434, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3407, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5354, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1570, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7060, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3348, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2916, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5797, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1797, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2831, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9266, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3252, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2881, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2671, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4895, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4155, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3072, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4195, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2392, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4733, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2469, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2852, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3861, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4890, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2328, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1903, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4599, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2154, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2715, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2000, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1391, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3408, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9423, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2485, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1620, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1106, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4456, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2077, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5151, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3320, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1562, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1968, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2901, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3063, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1030, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6415, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2861, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1874, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4955, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1085, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2063, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3893, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3733, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2799, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3112, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4153, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2197, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2740, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2986, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6579, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3050, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5312, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2843, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4618, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4491, grad_fn=<AddBackward0>) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2759, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6671, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3609, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2663, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3223, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5550, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3572, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3575, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1687, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1787, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5765, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2314, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2913, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3424, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4420, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5227, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3094, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2129, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3231, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.8486, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3771, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3835, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2505, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1998, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2733, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2442, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6047, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2729, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1778, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2703, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3810, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4535, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3349, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4514, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3186, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3801, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4547, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7894, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5134, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2858, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4761, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2639, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2937, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3374, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2889, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5639, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2615, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2435, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6482, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3954, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5454, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2985, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1208, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3829, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2573, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1797, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1624, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2582, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3501, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0379, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2472, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3279, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2346, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2747, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1747, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5077, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5509, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2020, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6667, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.0923, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3972, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6790, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2528, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1666, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1113, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2176, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4432, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.0852, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1474, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3218, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1366, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3522, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2205, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1308, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2006, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1519, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6590, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2267, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5994, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4963, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1080, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1192, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4394, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4760, grad_fn=<AddBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as func\n",
    "\n",
    "class myLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myLoss, self).__init__()\n",
    "        self.crossentropy = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, scores, true_y):\n",
    "        the_loss = 0.0\n",
    "        for i in range(true_y.shape[0]):\n",
    "            the_loss += self.crossentropy(scores[i], true_y[i])\n",
    "        return the_loss\n",
    "\n",
    "criterion = myLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "loss = 0.0\n",
    "for i in range(500):   # 训练500个句子\n",
    "    optimizer.zero_grad()\n",
    "    x = trainX[i:i+1]\n",
    "    out = net(x)\n",
    "    loss = criterion(out, trainY_vec[i:i+1])\n",
    "    print(loss, '\\n')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_vec_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0] \n",
      "\n",
      "[7, 12, 6, 10, 4, 8, 3, 2, 13, 0, 11, 13, 1, 14, 9, 7, 5] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [('O',0), ('B-LOC', 1), ('I-LOC', 2), ('B-PER', 3), ('I-PER', 4), ('B-ORG', 5), ('I-ORG', 6)])\n",
    "trainY = [[my_dic[tag] for tag in sentence] for sentence in trainY]\n",
    "print(trainY[0], '\\n')\n",
    "\n",
    "trainX = doc_vec_list\n",
    "print(trainX[0], '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
