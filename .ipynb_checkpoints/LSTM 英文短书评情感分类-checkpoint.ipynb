{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM 情感分析\n",
    "英文书评数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 待改进\n",
    "'You are not so bad',   被预测为0\n",
    "\n",
    "'You are not so good'      被预测为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections #用来统计词频\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理\n",
    "获取每条评论的最大长度, 以及所有评论中不重复词的个数 \n",
    "\n",
    "建立词到ID的映射, 保存在 word2ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每条数据的形式如下:\n",
    "\n",
    "1\tThe Da Vinci Code book is just awesome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\lib\\re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n",
      "D:\\study\\Anaconda\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "r1 = '[’\\n·＊!\"：#$%&\\'()◆●（）＠②*+,-../:;<=>?@，。?★、…【】《》？——“”‘’！[\\$$^_`{|}~]+'\n",
    "r2 = '[\\s]*'\n",
    "\n",
    "label = [] ; text = []\n",
    "max_lenth = 0   # 每个句子的最长长度, 40\n",
    "\n",
    "with open(r'D:\\CS\\dataset\\NLP\\英文情感分类.txt', 'r+', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r1, '', line)\n",
    "        line = re.split(r2, line)\n",
    "        if (len(line)-1) > max_lenth:\n",
    "            max_lenth = (len(line)-1)\n",
    "            \n",
    "        label.append(int(line[0]))\n",
    "        text.append(line[1:])\n",
    "        \n",
    "from gensim import corpora\n",
    "\n",
    "word2ID = corpora.Dictionary(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_word = len(word2ID.token2id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把每个文本中的词用ID表示, 每个文本长度为40, 不足的补零\n",
    "vec_text = []\n",
    "for i in text:\n",
    "    temp_list = []\n",
    "    for word in i:\n",
    "        if word in word2ID.token2id.keys():\n",
    "            temp_list.append(word2ID.token2id[word])\n",
    "        else:\n",
    "            temp_list.append(num_word+1)     # 不存在于字典的词用总词数+1填充\n",
    "            \n",
    "    bu0 = max_lenth - len(temp_list)\n",
    "    temp_list.extend([num_word+2] * bu0)\n",
    "    \n",
    "    vec_text.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(np.array(vec_text), label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 504, 2240,   75, ..., 2250, 2250, 2250],\n",
       "       [   3,    7,    2, ..., 2250, 2250, 2250],\n",
       "       [   3,    7,    2, ..., 2250, 2250, 2250],\n",
       "       ...,\n",
       "       [1378,   27,   54, ..., 2250, 2250, 2250],\n",
       "       [  27,  403,  400, ..., 2250, 2250, 2250],\n",
       "       [   3,    7,    2, ..., 2250, 2250, 2250]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "hidden_layer_size = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(2248+3, embedding_size))   # 将每个batch中的文本的每个词转化为词向量\n",
    "model.add(LSTM(hidden_layer_size, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑为什么第5行Embedding层要+3而不是+2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5668 samples, validate on 1418 samples\n",
      "Epoch 1/10\n",
      "5668/5668 [==============================] - 3s 447us/step - loss: 0.0358 - acc: 0.9935 - val_loss: 0.1319 - val_acc: 0.9753\n",
      "Epoch 2/10\n",
      "5668/5668 [==============================] - 2s 427us/step - loss: 0.0279 - acc: 0.9942 - val_loss: 0.1368 - val_acc: 0.9760\n",
      "Epoch 3/10\n",
      "5668/5668 [==============================] - 2s 437us/step - loss: 0.0278 - acc: 0.9952 - val_loss: 0.1166 - val_acc: 0.9788\n",
      "Epoch 4/10\n",
      "5668/5668 [==============================] - 2s 439us/step - loss: 0.0139 - acc: 0.9981 - val_loss: 0.0725 - val_acc: 0.9838\n",
      "Epoch 5/10\n",
      "5668/5668 [==============================] - 2s 436us/step - loss: 0.0092 - acc: 0.9988 - val_loss: 0.1386 - val_acc: 0.9767\n",
      "Epoch 6/10\n",
      "5668/5668 [==============================] - 3s 450us/step - loss: 0.0092 - acc: 0.9988 - val_loss: 0.1057 - val_acc: 0.9831\n",
      "Epoch 7/10\n",
      "5668/5668 [==============================] - 3s 554us/step - loss: 0.0046 - acc: 0.9993 - val_loss: 0.1098 - val_acc: 0.9810\n",
      "Epoch 8/10\n",
      "5668/5668 [==============================] - 3s 559us/step - loss: 0.0035 - acc: 0.9996 - val_loss: 0.1163 - val_acc: 0.9824.0036 - acc: 0.99\n",
      "Epoch 9/10\n",
      "5668/5668 [==============================] - 3s 556us/step - loss: 0.0022 - acc: 0.9998 - val_loss: 0.1185 - val_acc: 0.9803\n",
      "Epoch 10/10\n",
      "5668/5668 [==============================] - 3s 566us/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.1227 - val_acc: 0.9817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c1954450b8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 120\n",
    "num_epoch = 10\n",
    "\n",
    "model.fit(train_X, train_y, batch_size=batch_size, epochs=num_epoch, validation_data=(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vec(input_text):\n",
    "    input_text = input_text.lower()\n",
    "    input_text = re.sub(r1, '', input_text)\n",
    "    input_text = re.split(r2, input_text)\n",
    "    text_vec = []\n",
    "    \n",
    "    for word in input_text:\n",
    "        if word in word2ID.token2id.keys():\n",
    "            text_vec.append(word2ID.token2id[word])\n",
    "        else:\n",
    "            text_vec.append(num_word+1)     # 不存在于字典的词用总词数+1填充\n",
    "            \n",
    "    bu0 = max_lenth - len(text_vec)\n",
    "    text_vec.extend([num_word+2] * bu0)\n",
    "    return text_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\lib\\re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "input_text = ''\n",
    "text_vec = np.array(text2vec(input_text))\n",
    "text_vec = text_vec.reshape(-1, text_vec.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(text_vec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
