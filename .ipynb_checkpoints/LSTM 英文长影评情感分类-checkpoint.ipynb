{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM情感分类\n",
    "英文长影评数据集, 共1400条数据\n",
    "\n",
    "一共8万+个词, 每个文本最长2493个词, 模型的效果很差只有0.5, 或许是因为这个, 数据量太小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "D:\\study\\Anaconda\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import keras.preprocessing.text as T\n",
    "import re\n",
    "from gensim import corpora\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet(route, category):\n",
    "    files = os.listdir(route)   # 正类影评\n",
    "    \n",
    "    X = []; y = []\n",
    "\n",
    "    for file in files:\n",
    "        with open(route + file, 'r', encoding='UTF-8-sig') as f:\n",
    "            content = f.read()\n",
    "            X.append(content)\n",
    "            y.append(category)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_X, pos_y = loadDataSet(r'D:\\CS\\dataset\\NLP\\IMDB Movie Reviews Dataset\\aclImdb\\train\\pos\\\\', 1)\n",
    "neg_X, neg_y = loadDataSet(r'D:\\CS\\dataset\\NLP\\IMDB Movie Reviews Dataset\\aclImdb\\train\\neg\\\\', 0)   \n",
    "\n",
    "pos_X.extend(neg_X) ; pos_y.extend(neg_y)\n",
    "X = pos_X.copy() ; y = pos_y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(X):   # 将X中文本分词\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X: [text0, text1, text2]\n",
    "    Returns:\n",
    "        text_list: [['you', 'and', ...], ['what', 'honey', ...]]\n",
    "    \"\"\"\n",
    "    \n",
    "    text_list = []\n",
    "    for text in X:\n",
    "        text_list.append(T.text_to_word_sequence(text))\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bromwell',\n",
       " 'high',\n",
       " 'is',\n",
       " 'a',\n",
       " 'cartoon',\n",
       " 'comedy',\n",
       " 'it',\n",
       " 'ran',\n",
       " 'at',\n",
       " 'the',\n",
       " 'same',\n",
       " 'time',\n",
       " 'as',\n",
       " 'some',\n",
       " 'other',\n",
       " 'programs',\n",
       " 'about',\n",
       " 'school',\n",
       " 'life',\n",
       " 'such',\n",
       " 'as',\n",
       " 'teachers',\n",
       " 'my',\n",
       " '35',\n",
       " 'years',\n",
       " 'in',\n",
       " 'the',\n",
       " 'teaching',\n",
       " 'profession',\n",
       " 'lead',\n",
       " 'me',\n",
       " 'to',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'bromwell',\n",
       " \"high's\",\n",
       " 'satire',\n",
       " 'is',\n",
       " 'much',\n",
       " 'closer',\n",
       " 'to',\n",
       " 'reality',\n",
       " 'than',\n",
       " 'is',\n",
       " 'teachers',\n",
       " 'the',\n",
       " 'scramble',\n",
       " 'to',\n",
       " 'survive',\n",
       " 'financially',\n",
       " 'the',\n",
       " 'insightful',\n",
       " 'students',\n",
       " 'who',\n",
       " 'can',\n",
       " 'see',\n",
       " 'right',\n",
       " 'through',\n",
       " 'their',\n",
       " 'pathetic',\n",
       " \"teachers'\",\n",
       " 'pomp',\n",
       " 'the',\n",
       " 'pettiness',\n",
       " 'of',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'situation',\n",
       " 'all',\n",
       " 'remind',\n",
       " 'me',\n",
       " 'of',\n",
       " 'the',\n",
       " 'schools',\n",
       " 'i',\n",
       " 'knew',\n",
       " 'and',\n",
       " 'their',\n",
       " 'students',\n",
       " 'when',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'the',\n",
       " 'episode',\n",
       " 'in',\n",
       " 'which',\n",
       " 'a',\n",
       " 'student',\n",
       " 'repeatedly',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'burn',\n",
       " 'down',\n",
       " 'the',\n",
       " 'school',\n",
       " 'i',\n",
       " 'immediately',\n",
       " 'recalled',\n",
       " 'at',\n",
       " 'high',\n",
       " 'a',\n",
       " 'classic',\n",
       " 'line',\n",
       " 'inspector',\n",
       " \"i'm\",\n",
       " 'here',\n",
       " 'to',\n",
       " 'sack',\n",
       " 'one',\n",
       " 'of',\n",
       " 'your',\n",
       " 'teachers',\n",
       " 'student',\n",
       " 'welcome',\n",
       " 'to',\n",
       " 'bromwell',\n",
       " 'high',\n",
       " 'i',\n",
       " 'expect',\n",
       " 'that',\n",
       " 'many',\n",
       " 'adults',\n",
       " 'of',\n",
       " 'my',\n",
       " 'age',\n",
       " 'think',\n",
       " 'that',\n",
       " 'bromwell',\n",
       " 'high',\n",
       " 'is',\n",
       " 'far',\n",
       " 'fetched',\n",
       " 'what',\n",
       " 'a',\n",
       " 'pity',\n",
       " 'that',\n",
       " 'it',\n",
       " \"isn't\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = token(X)\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立字典\n",
    "dictionary = corpora.Dictionary(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最长文本的词数为: 2493\n",
      "总词数为: 88582\n"
     ]
    }
   ],
   "source": [
    "# 获取每个文本的最大词数\n",
    "length = 0\n",
    "for doc in X:\n",
    "    if len(doc) > length:\n",
    "        length = len(doc)\n",
    "\n",
    "num_word = max(dictionary.token2id.values()) + 1\n",
    "print('最长文本的词数为: %d' %length)\n",
    "print('总词数为: %d' %num_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs2idx(docs, dictionary):\n",
    "    temp_list = []\n",
    "    for doc in docs:\n",
    "        temp_list.append(dictionary.doc2idx(doc))\n",
    "        \n",
    "    return temp_list\n",
    "\n",
    "sequence_X = docs2idx(X, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对词ID序列文本padding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "padded_sequence_X = sequence.pad_sequences(sequence_X, length, padding='post', value=num_word+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练, 测试集\n",
    "train_X, test_X, train_y, test_y = train_test_split(padded_sequence_X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "hidden_layer_size = 32\n",
    "batch_size = 1000\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_word+2, output_dim=embedding_size))\n",
    "model.add(LSTM(hidden_layer_size, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 1000/20000 [>.............................] - ETA: 33:59 - loss: 0.6932 - acc: 0.5010"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "model.fit(train_X, train_y, epochs=10, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
