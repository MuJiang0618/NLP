{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM + CRF for NER\n",
    "BiLSTM的输入时文档向量, 并不需要对文档向量padding到一致的长度, 因为对应1个文档, BiLSTM输出1个feats矩阵(len_doc, num_tag), 将feats矩阵输入CRF, CRF最主要是要训练其转移矩阵(tag->tag), 所以即使feats矩阵行数不一, CRF都能用feats训练转移矩阵\n",
    "\n",
    "官方实现: https://pytorch.apachecn.org/docs/1.0/nlp_advanced_tutorial.html?h=Bidirection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "import nltk\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sentence = 10000\n",
    "with open(r'D:/CS/dataset/NLP/命名实体识别/单个字特征数据集/example.train', 'r', \n",
    "          encoding='utf-8') as f:\n",
    "    i = 0;\n",
    "    a = []\n",
    "    while(i < num_sentence):     # 读取了10000句预料\n",
    "        content = f.readline()\n",
    "        if content == '\\n':\n",
    "            i += 1\n",
    "        a.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(temp_list):\n",
    "    index_list = []\n",
    "    for i in range(len(temp_list)):\n",
    "        if temp_list[i] == '\\n':\n",
    "            index_list.append(i)\n",
    "    \n",
    "    pointer = 0\n",
    "    sentence_list = []\n",
    "    for index in index_list:\n",
    "        sentence_list.append(temp_list[pointer : index])\n",
    "        pointer = index + 1\n",
    "    return sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = get_sentences(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['但 O\\n',\n",
       " '是 O\\n',\n",
       " '， O\\n',\n",
       " '金 O\\n',\n",
       " '融 O\\n',\n",
       " '危 O\\n',\n",
       " '机 O\\n',\n",
       " '也 O\\n',\n",
       " '可 O\\n',\n",
       " '能 O\\n',\n",
       " '来 O\\n',\n",
       " '自 O\\n',\n",
       " '内 O\\n',\n",
       " '部 O\\n',\n",
       " '。 O\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[-2]   # 最后一句没有句号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去掉'\\n'和句号\n",
    "for sentence in sentence_list:\n",
    "    try:\n",
    "        sentence.remove('。 O\\n')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for i in range(len(sentence)):\n",
    "        sentence[i] = tuple(sentence[i].strip('\\n').split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('首', 'B-ORG'),\n",
       " ('届', 'I-ORG'),\n",
       " ('立', 'I-ORG'),\n",
       " ('法', 'I-ORG'),\n",
       " ('会', 'I-ORG'),\n",
       " ('选', 'O'),\n",
       " ('举', 'O'),\n",
       " ('是', 'O'),\n",
       " ('“', 'O'),\n",
       " ('港', 'B-LOC'),\n",
       " ('人', 'O'),\n",
       " ('治', 'O'),\n",
       " ('港', 'B-LOC'),\n",
       " ('”', 'O'),\n",
       " ('重', 'O'),\n",
       " ('要', 'O'),\n",
       " ('一', 'O'),\n",
       " ('步', 'O')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除特殊符号\n",
    "stop_words = '[a-zA-Z0-9’\\n·\\s＊!\"：#$%&\\'()◆●（）＠②*+,-./:;<=>?@，。?★、…【】《》？——“”‘’！[\\$$^_`{|}~]+'\n",
    "sentence_list = [[(word, tag) for word, tag in sentence if word not in stop_words] for sentence in sentence_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('首', 'B-ORG'),\n",
       " ('届', 'I-ORG'),\n",
       " ('立', 'I-ORG'),\n",
       " ('法', 'I-ORG'),\n",
       " ('会', 'I-ORG'),\n",
       " ('选', 'O'),\n",
       " ('举', 'O'),\n",
       " ('是', 'O'),\n",
       " ('港', 'B-LOC'),\n",
       " ('人', 'O'),\n",
       " ('治', 'O'),\n",
       " ('港', 'B-LOC'),\n",
       " ('重', 'O'),\n",
       " ('要', 'O'),\n",
       " ('一', 'O'),\n",
       " ('步', 'O')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [[word for word, tag in sentence] for sentence in sentence_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总词数:  3819\n",
      "最大文档长度 550\n"
     ]
    }
   ],
   "source": [
    "# 总词数\n",
    "dic = Dictionary(docs)\n",
    "vocab_size = max(dic.keys()) + 1\n",
    "print('总词数: ', vocab_size)     # 词id从0开始, 最大id 3818\n",
    "\n",
    "# 寻找最大句长\n",
    "sentences_len = [len(doc) for doc in docs]\n",
    "max_len_a_doc = max(sentences_len)\n",
    "print('最大文档长度', max_len_a_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看sentences_len发现绝大多数文档长度在120以内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_a_doc = 120\n",
    "trainY = [[tag for word, tag in sentence] for sentence in sentence_list]    # padding之前\n",
    "\n",
    "my_dic = dict([('O',0), ('B-LOC', 1), ('I-LOC', 2),\n",
    "            ('B-PER', 3), ('I-PER', 4), ('B-ORG', 5), ('I-ORG', 6)])\n",
    "def tag2idx(tag):\n",
    "    return my_dic[tag]\n",
    "\n",
    "# 先将tag映射为idx, 再对idx序列padding, 由于'O'对应idx为0, 所以句子padding部分都视作'O', 对应数字0\n",
    "# 不能用padding, 会使 B-LOC, I-LOC 都变成 B, I\n",
    "trainY_vec = [[my_dic[tag] for tag in sentence] for sentence in trainY]\n",
    "trainY_vec = sequence.pad_sequences(trainY_vec, maxlen=max_len_a_doc, value=0, padding='post')\n",
    "trainY_vec = torch.LongTensor(trainY_vec)\n",
    "trainY_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   7,   12,    6,   10,    4,    8,    3,    2,   13,    0,   11,\n",
       "         13,    1,   14,    9,    7,    5, 3819, 3819, 3819, 3819, 3819,\n",
       "       3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "       3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "       3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "       3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "       3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "       3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "       3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "       3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "       3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文本向量化\n",
    "doc_vec_list = [dic.doc2idx(doc) for doc in docs]\n",
    "# 不能填充-1 因为embedding矩阵中没有-1索引\n",
    "padded_doc_vec_list = sequence.pad_sequences(doc_vec_list, maxlen=120, value=3819, padding='post')\n",
    "trainX = np.array(padded_doc_vec_list)\n",
    "trainX[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM\n",
    "获取BiLSTM的输出feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "embedding_dim = 128\n",
    "lstm_dim = 128\n",
    "num_tag = 7\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, num_tag, embedding_dim, lstm_dim):  # vocab_size + padding的-1\n",
    "        super(Net, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_tag = num_tag\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_dim, num_layers=1, bidirectional=True)\n",
    "        self.lstm2tag = nn.Linear(lstm_dim*2, num_tag)   # BiLSTM 会把正反向lstm每个时间步的输出拼接为1行\n",
    "#         self.lstm2tag = nn.Softmax(num_tag)\n",
    "    def forward(self, x):\n",
    "        x = self.word_embeds(x)\n",
    "        x, hidden = self.lstm(x)\n",
    "        x = self.lstm2tag(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   7,   12,    6,   10,    4,    8,    3,    2,   13,    0,   11,   13,\n",
       "           1,   14,    9,    7,    5, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "        3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "        3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "        3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "        3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "        3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "        3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "        3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819,\n",
       "        3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819, 3819])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX = torch.LongTensor(trainX)\n",
    "trainX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0591,  0.1506, -0.0562, -0.0606,  0.0003,  0.1228, -0.0325],\n",
       "         [-0.0272,  0.0508,  0.0757,  0.1086,  0.0345,  0.0979, -0.0765],\n",
       "         [ 0.0990, -0.0354,  0.0378, -0.0061,  0.1308, -0.0080,  0.1091],\n",
       "         [-0.0752,  0.1256, -0.0580,  0.0247, -0.0555,  0.0964, -0.0149],\n",
       "         [-0.0490,  0.0461, -0.0128, -0.0365,  0.1063, -0.0036, -0.0747],\n",
       "         [ 0.0525,  0.0404, -0.0667, -0.0469,  0.0178,  0.0238, -0.0066],\n",
       "         [ 0.0265,  0.1006, -0.0326, -0.1025,  0.0963, -0.0026,  0.0924],\n",
       "         [-0.0206, -0.0020,  0.0400,  0.0441, -0.0567, -0.0271, -0.0354],\n",
       "         [-0.0612,  0.0293, -0.0967, -0.0140,  0.0030,  0.0160,  0.1477],\n",
       "         [ 0.0110,  0.0351, -0.0472,  0.0341,  0.0400,  0.0741, -0.0266],\n",
       "         [-0.0146,  0.0733, -0.0524,  0.0058,  0.0016,  0.0129, -0.0721],\n",
       "         [-0.0612,  0.0293, -0.0967, -0.0140,  0.0030,  0.0160,  0.1477],\n",
       "         [-0.1427,  0.0983,  0.0901,  0.0338,  0.0947,  0.0186, -0.0573],\n",
       "         [-0.1687, -0.0063, -0.1076, -0.1118,  0.1181,  0.0125, -0.0712],\n",
       "         [-0.0895,  0.0402, -0.1245, -0.0663, -0.0421,  0.0605,  0.0291],\n",
       "         [-0.0591,  0.1506, -0.0562, -0.0606,  0.0003,  0.1228, -0.0325],\n",
       "         [-0.0184,  0.0758, -0.0032,  0.0513,  0.0107,  0.0373, -0.0550],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380],\n",
       "         [-0.0130, -0.0314,  0.1281, -0.1626,  0.1194,  0.0479,  0.0380]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net(vocab_size+1, num_tag, embedding_dim, lstm_dim)\n",
    "feats = net(trainX[0:1])\n",
    "feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 尝试单独使用BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 120])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 120])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9825, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.9800, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.9855, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.9586, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.9411, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.9384, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.9062, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.8852, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.8607, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.9253, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.8418, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.8266, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.7961, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.9335, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.9405, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.7170, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.6551, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.7952, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.7041, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.6509, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.5832, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.5476, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.5641, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.5255, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.4335, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.4064, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.4115, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.3622, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.3230, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.2747, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.3804, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.2119, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.2748, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.2227, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.3405, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.6214, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.1492, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0368, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.5201, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.3083, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.2437, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9261, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.1412, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9014, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9853, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.1556, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9258, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.2154, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7459, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7412, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.9355, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6849, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6945, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.3680, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9598, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9775, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9427, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0977, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9412, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0865, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5638, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7560, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9217, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6803, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6709, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7053, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6524, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7077, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9946, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9185, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5236, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4922, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5621, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7070, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6189, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4858, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4278, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0400, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5642, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4740, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4081, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4518, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5798, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6805, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4717, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7334, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3749, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6913, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4919, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9485, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3744, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.4130, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5795, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5861, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5658, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5377, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3910, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9948, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4454, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3888, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9875, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3857, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.8714, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5291, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5014, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0906, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2797, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9647, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3427, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.4579, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5897, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5118, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4352, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.8136, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.8407, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5364, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6594, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5799, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3916, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3743, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4766, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3818, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3909, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7935, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2969, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6026, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4767, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3276, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5005, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3833, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3913, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.3193, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3672, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5753, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3601, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4916, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.8328, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5856, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6474, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7239, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2610, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6070, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7317, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3183, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7596, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9916, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2277, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2520, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6683, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9917, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4957, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0004, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3635, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9229, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5362, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4092, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3445, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3888, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5477, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4231, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5743, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3149, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2558, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5531, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2661, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6076, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0978, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2096, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3257, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2128, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2696, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3798, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7503, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4892, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7213, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6669, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6394, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3095, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3699, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2155, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7811, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4115, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6063, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3128, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7619, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6936, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3978, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1836, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3338, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3742, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3225, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3948, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5096, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3392, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6049, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9469, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6303, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3867, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4913, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4867, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2476, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6184, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3689, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3769, grad_fn=<AddBackward0>) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3807, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6486, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7679, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4429, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4441, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4016, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4155, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5124, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6908, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3979, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4145, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2447, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6809, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3869, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3440, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3594, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6581, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3635, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4351, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2650, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3864, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2123, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5630, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2631, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5534, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3910, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1495, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2551, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4477, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2967, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4549, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1608, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4548, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7391, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2111, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4593, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1851, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7823, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2829, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7516, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3369, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2031, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3912, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1955, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6191, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5308, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7407, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1775, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2468, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5865, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3854, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4845, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7217, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4861, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5123, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2766, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2779, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3802, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3690, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4417, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6891, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4807, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9189, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1440, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7247, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2976, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6002, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5849, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2948, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4214, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5470, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2712, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1873, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4383, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5894, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4229, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5159, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1889, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3777, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9397, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3044, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3046, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4340, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3223, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5349, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5120, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6064, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4505, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0172, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3241, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1487, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1462, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4825, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5202, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5588, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2289, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1301, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4585, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2167, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1328, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2824, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1640, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2129, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2579, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4509, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3579, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0375, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2229, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6614, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1449, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4136, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2755, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2090, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2224, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3807, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5888, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2563, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1306, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5959, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1203, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3934, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5685, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2032, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7736, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0470, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4524, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5136, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2642, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2460, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2296, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6962, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4489, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3632, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2565, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1579, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5238, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3307, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2636, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3582, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5138, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1626, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7387, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3355, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2814, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6119, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1787, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2914, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9606, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3115, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3050, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2888, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4877, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4291, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3146, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4210, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2701, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5098, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2797, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2949, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3997, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4877, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2503, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2049, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4667, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2132, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3000, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1993, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1580, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3575, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.9418, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2765, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1622, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1157, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4576, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2333, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5377, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3437, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1589, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1991, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3328, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3450, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1241, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6537, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3340, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2112, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5422, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1104, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2219, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4190, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4066, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2627, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3178, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4114, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2238, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2980, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3054, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7061, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3162, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5170, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3035, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4968, grad_fn=<AddBackward0>) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4553, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2663, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6760, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3471, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2873, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3050, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5858, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3543, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3524, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1967, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1747, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6016, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2534, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3347, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3545, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4738, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5240, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3342, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2459, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3102, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.8702, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4035, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4035, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2742, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2093, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2872, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2332, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6199, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2834, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1752, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2587, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4362, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5028, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3410, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4377, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3348, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4123, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4403, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.8133, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5543, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2851, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5118, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2746, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3090, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3381, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3027, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5694, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3080, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2562, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6586, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4527, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5562, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2920, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1302, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4237, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2503, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1793, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1715, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2798, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3799, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(1.0188, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2542, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3809, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2526, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3104, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1855, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5257, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5755, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1904, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7145, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.0961, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4179, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.7400, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2544, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1819, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1090, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2424, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4844, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.0805, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1574, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3474, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1412, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.3570, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2550, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1379, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2117, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1655, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6519, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.2404, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.6372, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.5201, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1158, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.1153, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4509, grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor(0.4480, grad_fn=<AddBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as func\n",
    "\n",
    "class myLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myLoss, self).__init__()\n",
    "        self.crossentropy = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, scores, true_y):\n",
    "        the_loss = 0.0\n",
    "        for i in range(true_y.shape[0]):\n",
    "            the_loss += self.crossentropy(scores[i], true_y[i])\n",
    "        return the_loss\n",
    "\n",
    "criterion = myLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "loss = 0.0\n",
    "for i in range(500):   # 训练500个句子\n",
    "    optimizer.zero_grad()\n",
    "    x = trainX[i:i+1]\n",
    "    out = net(x)\n",
    "    loss = criterion(out, trainY_vec[i:i+1])\n",
    "    print(loss, '\\n')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(trainX[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2129, -0.1440, -0.2700, -0.3013, -0.2119, -0.1916, -0.0448],\n",
       "        [ 1.1364, -0.2074, -0.2025, -0.2082, -0.1840, -0.2551, -0.1368],\n",
       "        [ 1.4429, -0.1783, -0.2016, -0.2114, -0.2896, -0.2035, -0.1007],\n",
       "        [ 1.8817, -0.1221, -0.3430, -0.4221, -0.2591, -0.3507, -0.2658],\n",
       "        [ 1.4655, -0.2979, -0.1774, -0.1898, -0.1961, -0.1219, -0.1612],\n",
       "        [ 1.6152, -0.2786, -0.1586, -0.3163, -0.2152, -0.3426, -0.1885],\n",
       "        [ 2.0086, -0.3190, -0.1961, -0.3322,  0.0572, -0.2588, -0.2307],\n",
       "        [ 1.9222, -0.2518, -0.2900, -0.4293, -0.3825, -0.3854, -0.1496],\n",
       "        [ 1.7112, -0.2136, -0.3931, -0.3807, -0.3521, -0.3792, -0.2158],\n",
       "        [ 1.7968, -0.3339, -0.2345, -0.2662, -0.2781, -0.3498, -0.2335],\n",
       "        [ 1.9462, -0.2802, -0.3822, -0.4253, -0.3978, -0.4022, -0.2506],\n",
       "        [ 1.1774, -0.2321, -0.1444, -0.2305, -0.1390, -0.0753, -0.1590],\n",
       "        [ 1.5405, -0.1377, -0.2857, -0.2663, -0.1958, -0.2769, -0.1474],\n",
       "        [ 1.1932, -0.2359, -0.1249, -0.2710, -0.0866, -0.2609, -0.1081],\n",
       "        [ 1.6004, -0.2639, -0.1539, -0.3074, -0.2148, -0.2859, -0.2326],\n",
       "        [ 2.3438, -0.3889, -0.4455, -0.4152, -0.3653, -0.3891, -0.3336],\n",
       "        [ 1.7214, -0.3783, -0.1920, -0.2791, -0.2915, -0.3015, -0.1751],\n",
       "        [ 1.4852, -0.1566, -0.1539, -0.2712, -0.2916, -0.3063, -0.2486],\n",
       "        [ 1.7710, -0.3029, -0.2796, -0.2929, -0.2345, -0.2141, -0.2488],\n",
       "        [ 2.1066, -0.2738, -0.3425, -0.2301, -0.4120, -0.5088, -0.3318],\n",
       "        [ 2.0048, -0.3647, -0.2492, -0.3461, -0.1973, -0.3914, -0.2174],\n",
       "        [ 1.5151, -0.2580, -0.2557, -0.1871, -0.1641, -0.1686, -0.1807],\n",
       "        [ 3.2719, -0.5050, -0.6558, -0.5598, -0.5290, -0.4905, -0.4358],\n",
       "        [ 3.6980, -0.6927, -0.5646, -0.6950, -0.5605, -0.5469, -0.5212],\n",
       "        [ 3.5341, -0.6065, -0.5142, -0.5859, -0.5132, -0.5968, -0.5308],\n",
       "        [ 3.6782, -0.7130, -0.7350, -0.7800, -0.4814, -0.6395, -0.3933],\n",
       "        [ 3.2460, -0.6779, -0.5862, -0.6630, -0.5007, -0.5862, -0.4825],\n",
       "        [ 3.4309, -0.5204, -0.5257, -0.6425, -0.5364, -0.5943, -0.6626],\n",
       "        [ 3.1669, -0.5970, -0.4774, -0.4866, -0.4976, -0.5447, -0.3253],\n",
       "        [ 4.1007, -0.6986, -0.6901, -0.6319, -0.7241, -0.7286, -0.5611],\n",
       "        [ 4.2324, -0.7602, -0.5847, -0.7921, -0.6662, -0.6244, -0.6099],\n",
       "        [ 4.5370, -0.7700, -0.8989, -0.8979, -0.6981, -0.6586, -0.6559],\n",
       "        [ 3.8766, -0.6380, -0.5886, -0.7723, -0.6539, -0.5553, -0.6882],\n",
       "        [ 4.2525, -0.7834, -0.7704, -0.8714, -0.6572, -0.6923, -0.6504],\n",
       "        [ 3.5311, -0.6840, -0.5025, -0.7273, -0.4610, -0.6303, -0.5814],\n",
       "        [ 4.4168, -0.8305, -0.7024, -0.9036, -0.6178, -0.6901, -0.6477],\n",
       "        [ 4.0620, -0.7968, -0.6852, -0.7632, -0.6571, -0.4272, -0.5661],\n",
       "        [ 4.1098, -0.7881, -0.7224, -0.9018, -0.5489, -0.5409, -0.7028],\n",
       "        [ 3.5735, -0.6906, -0.5803, -0.6254, -0.4726, -0.4249, -0.5924],\n",
       "        [ 4.1831, -0.7330, -0.7629, -0.7811, -0.7131, -0.5561, -0.6885],\n",
       "        [ 3.9261, -0.6961, -0.6411, -0.8327, -0.5892, -0.5604, -0.7029],\n",
       "        [ 4.5866, -0.9225, -0.6338, -0.8301, -0.6403, -0.6826, -0.7354],\n",
       "        [ 3.7894, -0.6870, -0.6217, -0.8582, -0.5079, -0.6584, -0.5987],\n",
       "        [ 4.3739, -0.8561, -0.8109, -0.8688, -0.7216, -0.6275, -0.6482],\n",
       "        [ 4.7133, -0.8674, -0.7504, -0.9303, -0.6896, -0.6609, -0.5968],\n",
       "        [ 4.8817, -0.7978, -0.9704, -0.9424, -0.7795, -0.7252, -0.7217],\n",
       "        [ 3.3486, -0.6968, -0.4716, -0.7325, -0.5151, -0.6287, -0.5032],\n",
       "        [ 3.9548, -0.6937, -0.5592, -0.7157, -0.5934, -0.6052, -0.5417],\n",
       "        [ 4.8623, -0.9730, -0.8790, -0.8618, -0.6844, -0.7098, -0.7468],\n",
       "        [ 4.0381, -0.8197, -0.5949, -0.7513, -0.5812, -0.6512, -0.5235],\n",
       "        [ 4.2707, -0.8624, -0.7279, -0.7974, -0.5074, -0.6876, -0.7387],\n",
       "        [ 4.3892, -0.8298, -0.7849, -0.7695, -0.8081, -0.7415, -0.6471],\n",
       "        [ 4.2437, -0.7042, -0.7130, -0.9482, -0.5554, -0.5570, -0.7650],\n",
       "        [ 3.9603, -0.7308, -0.6494, -0.8906, -0.4974, -0.5821, -0.6259],\n",
       "        [ 4.0059, -0.7427, -0.7400, -0.7283, -0.7496, -0.7081, -0.6154],\n",
       "        [ 4.3555, -0.6842, -0.6010, -0.7997, -0.5995, -0.5781, -0.5886],\n",
       "        [ 4.3957, -0.8455, -0.6996, -0.8427, -0.7017, -0.6500, -0.7128],\n",
       "        [ 4.6873, -0.8704, -0.7442, -0.8615, -0.6618, -0.7349, -0.7713],\n",
       "        [ 5.1393, -0.8624, -1.0058, -1.0285, -0.8209, -0.7621, -0.8055],\n",
       "        [ 4.3896, -0.8434, -0.8130, -0.9142, -0.6511, -0.6461, -0.6529],\n",
       "        [ 4.4999, -0.8116, -0.7077, -0.8356, -0.7005, -0.7803, -0.7029],\n",
       "        [ 4.5922, -0.7870, -0.7228, -0.9449, -0.6930, -0.7391, -0.6433],\n",
       "        [ 4.8536, -0.8633, -0.8087, -0.8306, -0.6225, -0.6661, -0.6941],\n",
       "        [ 5.1856, -0.8744, -1.0349, -1.0276, -0.8349, -0.7709, -0.8115],\n",
       "        [ 4.4803, -0.7506, -0.6965, -0.9035, -0.7591, -0.6484, -0.8307],\n",
       "        [ 3.9966, -0.6501, -0.6333, -0.6165, -0.4900, -0.4801, -0.6117],\n",
       "        [ 4.8906, -0.9816, -0.6853, -0.9231, -0.7193, -0.7454, -0.7890],\n",
       "        [ 4.2535, -0.7567, -0.8698, -0.8350, -0.7176, -0.6887, -0.7065],\n",
       "        [ 3.9190, -0.7530, -0.6072, -0.6649, -0.6112, -0.6604, -0.5280],\n",
       "        [ 4.5388, -0.8048, -0.9038, -0.8231, -0.6634, -0.5852, -0.6587],\n",
       "        [ 5.1637, -0.8704, -1.0222, -1.0364, -0.8366, -0.7660, -0.8093],\n",
       "        [ 4.7522, -0.8888, -0.7745, -0.8778, -0.7702, -0.7012, -0.7649],\n",
       "        [ 4.6621, -0.8799, -0.7358, -0.8439, -0.6312, -0.7428, -0.7664],\n",
       "        [ 5.1618, -0.8828, -1.0116, -1.0362, -0.8281, -0.7610, -0.8142],\n",
       "        [ 4.4576, -0.9023, -0.7295, -0.8713, -0.6531, -0.6253, -0.7821],\n",
       "        [ 4.4423, -0.8146, -0.7247, -0.9648, -0.6387, -0.7277, -0.6448],\n",
       "        [ 4.8785, -0.9379, -0.8983, -0.9759, -0.7964, -0.7503, -0.7566],\n",
       "        [ 4.5452, -0.7964, -0.8493, -1.0038, -0.7612, -0.6386, -0.7562],\n",
       "        [ 8.1592, -1.4378, -1.3773, -1.5799, -1.2782, -1.2649, -1.2024],\n",
       "        [ 8.1412, -1.4414, -1.3625, -1.5632, -1.2719, -1.2530, -1.2150],\n",
       "        [ 8.1068, -1.4364, -1.3645, -1.5631, -1.2917, -1.2543, -1.2152],\n",
       "        [ 8.2299, -1.4702, -1.3879, -1.5902, -1.2859, -1.2745, -1.2266],\n",
       "        [ 8.2312, -1.4711, -1.3866, -1.5895, -1.2838, -1.2737, -1.2277],\n",
       "        [ 8.2275, -1.4704, -1.3839, -1.5893, -1.2859, -1.2746, -1.2277],\n",
       "        [ 8.2300, -1.4696, -1.3854, -1.5892, -1.2829, -1.2742, -1.2264],\n",
       "        [ 8.2294, -1.4699, -1.3856, -1.5886, -1.2832, -1.2722, -1.2257],\n",
       "        [ 8.2311, -1.4702, -1.3871, -1.5918, -1.2860, -1.2753, -1.2268],\n",
       "        [ 8.2297, -1.4705, -1.3860, -1.5915, -1.2861, -1.2761, -1.2276],\n",
       "        [ 8.2293, -1.4701, -1.3848, -1.5896, -1.2850, -1.2724, -1.2288],\n",
       "        [ 8.2336, -1.4707, -1.3883, -1.5901, -1.2831, -1.2726, -1.2270],\n",
       "        [ 8.2288, -1.4717, -1.3865, -1.5908, -1.2848, -1.2755, -1.2263],\n",
       "        [ 8.2313, -1.4706, -1.3880, -1.5914, -1.2833, -1.2733, -1.2255],\n",
       "        [ 8.2308, -1.4719, -1.3883, -1.5908, -1.2834, -1.2730, -1.2291],\n",
       "        [ 8.2311, -1.4708, -1.3885, -1.5912, -1.2855, -1.2749, -1.2265],\n",
       "        [ 8.2315, -1.4699, -1.3880, -1.5899, -1.2864, -1.2734, -1.2274],\n",
       "        [ 8.2306, -1.4701, -1.3878, -1.5894, -1.2845, -1.2746, -1.2260],\n",
       "        [ 8.2273, -1.4689, -1.3839, -1.5913, -1.2853, -1.2760, -1.2275],\n",
       "        [ 8.2300, -1.4699, -1.3870, -1.5912, -1.2839, -1.2748, -1.2248],\n",
       "        [ 8.2262, -1.4712, -1.3879, -1.5890, -1.2856, -1.2739, -1.2255],\n",
       "        [ 8.2301, -1.4702, -1.3867, -1.5915, -1.2847, -1.2761, -1.2264],\n",
       "        [ 8.2303, -1.4693, -1.3860, -1.5897, -1.2874, -1.2728, -1.2266],\n",
       "        [ 8.2336, -1.4712, -1.3854, -1.5922, -1.2855, -1.2748, -1.2295],\n",
       "        [ 8.2325, -1.4698, -1.3881, -1.5928, -1.2873, -1.2750, -1.2264],\n",
       "        [ 8.2291, -1.4708, -1.3880, -1.5902, -1.2858, -1.2743, -1.2268],\n",
       "        [ 8.2314, -1.4724, -1.3875, -1.5888, -1.2815, -1.2729, -1.2274],\n",
       "        [ 8.2291, -1.4713, -1.3835, -1.5862, -1.2829, -1.2719, -1.2277],\n",
       "        [ 8.2326, -1.4693, -1.3884, -1.5922, -1.2831, -1.2741, -1.2262],\n",
       "        [ 8.2289, -1.4708, -1.3843, -1.5881, -1.2866, -1.2728, -1.2262],\n",
       "        [ 8.2311, -1.4712, -1.3880, -1.5919, -1.2854, -1.2748, -1.2262],\n",
       "        [ 8.2298, -1.4693, -1.3861, -1.5889, -1.2869, -1.2722, -1.2266],\n",
       "        [ 8.2311, -1.4706, -1.3854, -1.5904, -1.2827, -1.2743, -1.2267],\n",
       "        [ 8.2334, -1.4716, -1.3868, -1.5909, -1.2839, -1.2739, -1.2274],\n",
       "        [ 8.2344, -1.4726, -1.3882, -1.5916, -1.2845, -1.2740, -1.2281],\n",
       "        [ 8.2359, -1.4716, -1.3887, -1.5929, -1.2841, -1.2756, -1.2282],\n",
       "        [ 8.2358, -1.4729, -1.3882, -1.5920, -1.2842, -1.2754, -1.2282],\n",
       "        [ 8.2376, -1.4728, -1.3889, -1.5923, -1.2851, -1.2758, -1.2281],\n",
       "        [ 8.2350, -1.4725, -1.3892, -1.5926, -1.2853, -1.2755, -1.2288],\n",
       "        [ 8.2337, -1.4730, -1.3879, -1.5895, -1.2830, -1.2736, -1.2267],\n",
       "        [ 8.2343, -1.4727, -1.3882, -1.5912, -1.2837, -1.2756, -1.2278],\n",
       "        [ 8.2343, -1.4728, -1.3874, -1.5919, -1.2836, -1.2758, -1.2289]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY_vec[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
